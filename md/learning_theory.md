# 过拟合和欠拟合
在统计学中，拟合指的是你逼近目标函数的远近程度。

过拟合指的是模型对于训练数据拟合程度过当的情况。当某个模型过度的学习训练数据中的细节和噪音，以至于模型在新的数据上表现很差，我们称过拟合发生了。这意味着训练数据中的噪音或者随机波动也被当做概念被模型学习了。而问题就在于这些概念不适用于新的数据，从而导致模型泛化性能的变差。过拟合更可能在无参数非线性模型中发生，因为学习目标函数的过程是易变的具有弹性的。同样的，许多的无参数器学习算法也包括限制约束模型学习概念多少的参数或者技巧。

欠拟合指的是模型在训练和预测时表现都不好的情况。一个欠拟合的机器学习模型不是一个良好的模型并且由于在训练数据上表现不好这是显然的。欠拟合通常不被讨论，因为给定一个评估模型表现的指标的情况下，欠拟合很容易被发现。矫正方法是继续学习并且试着更换机器学习算法。

# 风险函数
## 损失函数
在介绍很多监督学习算法时，都会给出损失函数，然后把监督学习问题变成一个关于损失函数的最优化问题。

设学习模型的假设函数记为$$h$$，样本的特征集和目标分别为$$x,y$$，则$$h(x)$$与样本结果$$y$$可能一致，也可能存在一定的误差，所以我们用一个函数来度量预测错误的程度，这个函数就是损失函数。损失函数是$$h(x)$$和$$y$$的函数，因为记为$$L(h(x), y)$$。

常用的损失函数有：
1. 0-1损失函数
```math
L(h(x), y) = \left\{\begin{matrix}
1, &  y \neq  h(x)
\\0, &  y = h(x)
\end{matrix}\right.
```
2. 平方损失函数
```math
L(h(x), y) = (y - h(x))^{2}
```

3. 对数损失函数
```math
L(p(y|x), y) = -\log p(y|x)
```

4. 绝对损失函数
```math
L(h(x), y) = |y - h(x)|
```

5. hinge损失函数
```math
L(h(x), y) = max(0, 1 - y \cdot h(x));\quad y = \pm 1;
```

6. 指数损失函数
```math
L(h(x), y) = \exp(-y \cdot h(x))
```

## 期望风险
对我们的学习模型来说，当然是损失越小越好，假定$$x, y$$是随机变量，服从联合分布$$P(x, y)$$，那么损失的期望值为：
```math
R_{exp}(h) = E_{p}[L(h(x), y)] = \int_{x \times y} L(h(x), y)P(x, y) dxdy
```

此函数称为期望风险函数，学习的目标就是选择期望风险最小的模型。但是由于联合分布$$P(x, y)$$未知，因为$$R_{exp}$$无法直接计算。
## 经验风险
给定一个训练数据集
```math
T = \{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})\}
```

我们把训练数据集的平均损失称为经验风险函数
```math
R_{emp}(h) = \frac{1}{m}\sum_{i=1}^{m}L(h(x^{(i)}), y^{(i)})
```

根据概率论的大数定律，随着样本数量$$m$$的增加，经验风险(样本均值)会接近于期望风险(随机变量的期望)。所以我们很容易想到用经验风险去估计期望风险。因此一般解决学习问题的策略就是经验风险最小化(ERM)，即
```math
\hat{h} = \arg \min \limits_{h} R_{emp}(h)
```

## 泛化能力
于现实中，训练样本的数目总是有限的，所以用经验风险去估计期望风险的结果可能并不是很理想。我们用从已知训练集中的样本学习到的模型对未知数据的预测能力叫做泛化能力。我们在评估模型的泛化能力时，最常用方法是通过测试样本的误差来评估。但是测试数据集的样本数目也是有限的，因此这种方法并不是十分准确。下面将对模型的泛化能力在理论上给出一些分析。

给定数据集
```math
T = \{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})\}
```

设假设函数的集合为$$H$$，对于任何$$h \in H$$，定义其训练误差为
```math
\hat{\varepsilon}(h) = \frac{1}{m}\sum_{i=1}^{m}L(h(x^{(i)}), y^{(i)})
```
即经验风险

通过已知训练集学习的模型即为
```math
\hat{h} = \arg \min \limits_{h} \hat{\varepsilon}(h)
```

我们用泛化误差来表示模型的泛化能力：
```math
\varepsilon(h) = E_{P}[L(\hat{h}(x), y)]
```
事实上，泛化误差就是学到的模型的期望风险。

接下来，我们会证明，当样本数目很大是，一般误差会很接近泛化误差，同时也给出量化分析误差的方法。

在介绍一致收敛原理之前，先简单给出证明时需要用到的两个引理：
1. Union Bound
对于$$A_{1}, A_{2}, \cdots, A_{n}$$这n个事件，有
```math
P(A_{1} \cup A_{2} \cup \cdots \cup A_{n}) = P(A_{1}) + P(A_{2}) + \cdots +
```
```math
P(A_{n}) - P(A_{1} \cap A_{2}) - P(A_{1} \cap A_{3}) -  \cdots
```
```math
\leqslant P(A_{1}) + P(A_{2}) + \cdots + P(A_{n})
```

2. [Hoeffding不等式](https://en.wikipedia.org/wiki/Hoeffding%27s_inequality)
令$$X_{1}, X_{2}, \cdots, X_{n}$$为n个独立分布的随机变量，且$$X_{i} \in [a_{i}, b_{i}]$$，
令
```math
S_{n} = \frac{1}{n}\sum_{i=1}^{n}X_{i}, i = 1, 2, \cdots, n
```

对于任意固定的实数$$t \gt 0$$，则有
```math
P(|S_{n} - E(S_{n})| \geqslant t ) \leqslant 2\exp(-\frac{2n^{2}t^{2}}{\sum_{i=1}^{n}(b_{i} - a_{i})^{2}})
```

对于二分类问题，$$y \in \{0, 1\}$$，则损失函数的取值区间为$$[0, 1]$$，又因为$$R_{emp}$$就是随机变量$$L(h(x), y)$$的样本均值，$$R_{exp}$$就是随机变量$$L(h(x), y)$$的样本期望，那么根据Hoeffding不等式有

```math
P(|R_{emp} - R_{exp}| \geqslant t ) \leqslant 2\exp(-2nt^{2})
```
对于有限的假设函数的集合$$H:\{h_{1}, h_{2}, \cdots, h_{m}\}$$，
```math
P(\exists h \in H; |\hat{\varepsilon}(h) - \varepsilon(h)| \geqslant t)  = P(\cup_{h \in H}{|\hat{\varepsilon}(h) - \varepsilon(h)| \geqslant t})
```
```math
\leqslant \sum_{h \in H} P(|\hat{\varepsilon}(h) - \varepsilon(h)| \geqslant t)
```
```math
\leqslant 2m\exp(-2nt^{2})
```
则
```math
P(\forall h \in H; |\hat{\varepsilon}(h) - \varepsilon(h)| \leqslant t) \geqslant 1 - 2m\exp(-2nt^{2})
```
当$$n$$很大时，$$\exp(-2nt^{2})$$会很小，这样，$$\hat{\varepsilon}(h)$$和$$\varepsilon(h)$$的差有很大的概率在一个固定的实数范围内，这就是一致收敛原理，即随着样本数目的增加，训练误差会逼近泛化误差。我们这里讨论的都是针对二分类问题的，相对其他问题，这个结论会复杂的多。

根据一致收敛原理，我们还可以得到以下的结论：

```math
P(\forall h \in H; |\hat{\varepsilon}(h) - \varepsilon(h)| \leqslant t)
```
```math
\geqslant 1 - 2m\exp(-2nt^{2})
```
```math
\geqslant 1 - \delta
```
可得
```math
n \geqslant \frac{1}{2t^{2}}\log\frac{2m}{\delta}
```
$$\delta$$是表示我们可以接受的概率，$$m$$是模型假设函数的集合的大小。$$t$$是我们可以接受的误差范围，根据这几个变量，我们就可以量化算法稳定所需的样本的数目，因为这个公式也叫做算法的样本复杂度。

同理可得
```math
t = \sqrt{\frac{1}{2n}\log\frac{2m}{\delta}}
```
这个公式给出了训练误差和泛化误差的差距的量化方法。

再看
```math
\varepsilon(\hat{h}) \leqslant \hat{\varepsilon}(\hat{h}) + t
```

这个不等式给出了泛化误差的上界，那么一个模型的泛化能力到底如何呢？我们可以通过以下的推导得到：
令
```math
h^{*} = \arg\min\limits_{h \in H} \varepsilon(h)
```
即$$h^{*}$$是集合$$H$$中使得泛化误差最小的函数，也就是说$$h^{*}$$是泛化能力最好的模型。

```math
\varepsilon(\hat{h}) \leqslant \hat{\varepsilon}(\hat{h}) + t \leqslant \hat{\varepsilon}(h^{*}) + t
```
```math
\leqslant \varepsilon(h^{*}) + t + t =  \varepsilon(h^{*}) + 2t
```

其中，第一个不等式是根据一致收敛原理得到的，第二个不等式是根据$$\hat{h}$$的定义得到的，因为它是训练误差最小的假设函数，第三个不等式还是根据一致收敛原理得到的。这表明，当一致收敛原理成立时，我们通过经验风险最小化得到的模型的泛化误差和泛化能力最好的模型的泛化误差的差距是$$2t$$。

当$$m$$变大，即集合$$H$$的元素变多了，可选择的假设函数也变多了，那么我们有可能会选到泛化能力更好的函数了。即$$\varepsilon(h^{*})$$可能会变小，但是 $$t = \sqrt{\frac{1}{2n}\log\frac{2m}{\delta}}$$，若$$m$$变大，$$t$$也会变大，所以并不是模型越复杂($$m$$越大)越好，若要使模型有的泛化能力好，需要权衡前后两部分，选择一个最优值。

# Vapnik-Chervonenkis Theory
## 无限集合的情况
上面在介绍一致收敛原理时，我们的假设函数空间$$H$$是一个有限的集合，而在实际应用中，很多假设函数空间的元素的个数是无限的，例如，在Logistic回归中，参数$$\theta$$可以有无限个可能的值，所以假设函数空间的元素也是无限的。

再看泛化误差的上界：
```math
\varepsilon(\hat{h}) \leqslant \hat{\varepsilon}(\hat{h}) + t
```
而$$\lim\limits_{m \to \infty}t = \infty$$，因此这上界过大，我们不能直接把有限假设空间的结论推广到无限假设空间的情况中去。

无限假设空间的情况时，上面的上界过大的原因就是在我们用Union Bound来计算概率时，不等式的右边被放的过大，因为这无限个事件并不是独立的，其中有很多是重复的。这样，我们的想法就是如果我们能把这无限个假设函数分成有限个分类，再证明每个分类的某些性质是一样的，同一分类我们只需要计算一次，其他的事件在某些情况下可以从不等式的右边去掉。这样就可以缩小这个上界了。

令假设函数分类的个数为$$M_{H}$$。

首先，要学习的训练集肯定是有限的，即$$n$$个样本。那么对于而分类问题，我们就有$$2^{n}$$个分类的可能。这样，每一种分类的方式看成一种划分假设函数的类别，这无限个假设函数可以被分为$$2^{n}$$个类。

但是$$t = \sqrt{\frac{1}{2n}\log\frac{2m}{\delta}}$$，当$$M_{H}=2^{n}$$时，我们用$$M_{H}$$来代替$$m$$，还是需要很大的$$n$$，$$t$$才能收敛到0。所以我们还需要继续缩小$$M_{H}$$，最好$$M_{H}$$是关于$$n$$的一个多项式，这样就可以保证对于任何$$n$$，t都是收敛到0的。

## VC Dimension
下面，我们以二维平面上的线性分类器为例来介绍VC Dimension的概念。
我们令$$H$$为以二维平面上的线性分类器的集合。我们用圈圈表示正样本，用叉叉表示负样本。分别观察当$$n=2,3,4$$时的情况。
![image](http://oirw7ycq0.bkt.clouddn.com/shatter_1.png)
![image](http://oirw7ycq0.bkt.clouddn.com/shatter_2.png)

当$$n=2$$时，至少有一个2个点的数据集，$$H$$中存在有一条直线，可以把这2个点组成的4种情况都分开。当$$n=3$$时，我们也可以找到一个3个点的数据集和一条直线，让这条直线把3个点组成的8种情况都分开。但是当$$n=4$$时就发生变化了，这时我们发现，最多我们可以分开16种情况种的14种。

当存在某个有n个点的数据集，假设函数空间$$H$$中至少有一个假设函数可以把这n个点组成的$$2^{n}$$中情况都按正负样本的分类分开来，我们就说H可以shatter $$n$$个点。很容易观察到，如果$$H$$不能shatter $$n$$个点，那么对于$$n + 1, n + 2, \cdots$$，这以后的点，$$H$$都是不能shatter的，这个结论可以用数学归纳法证明，因为遮住一个点，$$n + 1$$个点的情况里是包含$$n$$个点中的所有情况的。这里我们引出VC Dimension的概念：当$$H$$只能shatter $$n$$个点，对于$$n + 1, n + 2, \cdots$$，这以后的情况都不能shatter，我们就说$$H$$的VC Dimension是$$n$$，记为$$D_{vc} = n$$。这个概念是用两个统计学家的名字来命名的，VC Dimension 即 “Vapnik-Chervonenkis Dimension”。

VC Dimension是机器学习理论中非常重要的一个概念，当某个模型的VC Dimension越小时，就表示模型越简单，VC Dimension越大时，模型就越复杂。

注意到VC Dimension也可以是无穷大，例如$$H$$为二维平台上的凸集，那么对于任何n个点，我们把这n个点分散到一个圆周上。假设正样本的个数为$$k$$，我们用在直线把这$$k$$个点连接成一个$$k$$边形，这个$$k$$边形一定是一个凸多边形，然后我们把$$k$$边形的每条边稍微向远离圆心的方向移动一些，但是不要碰到其他的负样本的点，这样，就可以把这$$n$$个点shatter了。

## VC Bound
上面我们提到，当$$n=4$$时，二维平面上的线性分类器最多可以分开的16种情况中的14种，我们把$$H$$中的函数最多可以分开的情况看成一个关于数据集中点个数的函数，叫做成长函数，记为$$M_{H}(n)$$。显然，对于二维平面上的线性分类器组成的集合，$$M_{H}(2) = 4$$，$$M_{H}(3) = 8$$，$$M_{H}(4) = 14$$，同样可以通过枚举得到$$M_{H}(5) = 22$$。

随着$$n$$的增大，$$M_{H}$$的增长速度并不是很快。似乎我们用$$M_{H}(n)$$来代替$$|H|$$是可行的，但是我们要需要证明，$$M_{H}(n)$$复杂度不大于$$n$$的某个多项式。

假设$$D_{vc}(H) = n$$，那么当有$$k=n+1$$时，$$H$$是不能shatter的，我们称$$k$$是$$H$$的break point。

我们把成长函数的上界记为$$B(n, k)$$，其中$$n$$为点的个数，$$k$$为break point。例如$$B(4, 4)$$就表示有一共有4个点，break point是4的时候成长函数的上界。

下面几个是可以很容易推导出来的
$$B(3,2)=4$$：当有3个点时，如果有两个点不能shatter，最多只能最多只能分开4种情况，如果比4种情况更多，比如5种，我们遮住其中的一个点，其他2个点就可能会出现4种不同的情况，这就和break point是2矛盾了。
$$B(n,1)=1$$：如果一个点都不能shatter，那上界就是1了
$$B(n,k)=2^{n}, n \lt k$$：如果$$n \lt k$$，那就是说这n个点是可以被shatter的，所以上限就是$$2^{n}$$
$$B(n, n)=2^{n} - 1$$：如果break point就是$$n$$，那就是说$$n-1$$个点是可以shatter的，但是n个点是不能shatter的，所以$$B(n, n) < 2^{n}$$,那在没有别的约束的情况下：$$B(n, n) = 2^{n} - 1$$。

下面我们再看看$$B(3,2)$$，由上面的推导知：$$B(2,2) = 3$$，当有3个点时，如果有两个点不能shatter，最多只能最多只能分开4种情况，如果比4种情况更多，比如5种，我们遮住其中的一个点，其他2个点就可能会出现4种不同的情况，这就和break point是2矛盾了。

可以证明：
```math
B(n, k) \leqslant B(n - 1, k) + B(n - 1, k -1)
```
用归纳法可以得到：
```math
B(n, k) \leqslant \sum_{i = 1}^{k-1}C^{i}_{n}
```

不等式右边展开后，指数最大的项就是$$n^{k-1}$$，这正是我们想要的关于$$n$$的多项式表达式，即：
```math
M_{H}(n) \leqslant B(n, k) \leqslant \sum_{i = 1}^{D_{vc}}C^{i}_{n}
```
最后我们用$$M_{H}(n)$$来代替一致收敛原理中的$$m=|H|$$，可以得到下面的VC Bound：
```math
P(\exists h \in H; |\hat{\varepsilon}(h) - \varepsilon(h)| \geqslant t)
```
```math
\leqslant  4M_{H}(2n)\exp(-\frac{1}{8}nt^{2})
```

## VC Dimension的意义
VC Dimension代表了一个模型的可调整的程度，VC Dimension越多，表明这个模型也调整的参数也就越多，即模型的表达能力也就越强，训练误差本身会很小。但是当VC Dimension太大时，$$M_{H}(n)$$会变大，训练误差和泛化误差的差距就会变大。当当VC Dimension太小时，$$M_{H}(n)$$也会变小，训练误差会更接近泛化误差，但是由于可以选择的假设函数变少，可能会没有足够多的假设函数给我们选择。所以VC Dimension是机器学习中一个很重要的概念。


# 模型选择
上面我们证明了经验风险最小化的方法对处理某些监督学习的问题是可行的，同时，我们也量化了经验风险最小化得出的模型的泛化能力。下面我们给出两种模型选择的方法，这两种方法都会综合考虑经验风险和泛化能力。

## 交叉验证
简单的交叉验证法就是将已知的数据分为两个部分，一个部分作为训练集(一般占所有数据的70%)，另外一部分作为验证集。然后用训练集在各种条件下训练模型，从而得到不同的模型，在验证集上评价各个模型的测试误差，选出测试误差最小的模型。

复杂一些的交叉验证法，可以随机的把已知的数据集分成$$N$$个大小相同，没有重复元素的子集，用$$N-1$$个子集训练模型，然后再用剩下的子集做验证。将这一过程对可能的$$N$$中选择重复进行，最后选出平均测试误差最小的模型。
## 正则化
正则化是在经验风险上加上一个正则化项，正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。很多情况下，可以用模型参数的范数作为正则化项。

正则化后的目标优化函数有一下的一般形式：
```math
\min\limits_{h \in H} \frac{1}{m}\sum_{i=1}^{m}L(h(x^{(i)}), y^{(i)}) + \lambda J(h), \quad  \lambda \geqslant 0
```
在求上面的最优化问题时，因为$$\lambda \geqslant 0$$，就要求$$J(h)$$尽可能的小。例如我们选择模型参数的L1范数作为$$J(h)$$，那么在加上正则化选项后，就会有很多的参数的值为0，从而使模型简化。正则化符合奥卡姆剃刀原理：在所有的模型中，能够很好的解释已知数据并且十分简单的模型才是做好的。

下面我们从贝叶斯统计角度来看看正则化的合理性。

假定模型中的参数向量是$$\theta$$，之前我们都是把参数$$\theta$$看成是一个固定但是未知的定值，然后用最大似然估计来求出$$\theta$$的值，这种做法是统计学中频率学派的做法，还有一派叫做贝叶斯学派，他们会把$$\theta$$看成一个服从某种分布的随机变量，这个分布叫做先验分布。

以分类问题为例，设有样本集$$D = \{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})\}$$

我们的模型就是通过条件概率$$p(y|x)$$来判断某个样本的类别。
一般我们认为$$p(y|x)$$依赖与参数$$\theta$$，所以记作$$p(y|x;\theta)$$，但是在把$$\theta$$看成一个随机变量后，这个条件概率变成了$$p(y|x,\theta)$$。

似然函数
```math
p(D|\theta) = \prod_{i=1}^{m}p(y^{(i)}|x^{(i)},\theta)
```
我们把$$p(\theta|D)$$叫做后验分布，他表示在我们知道一组数据集后，对先验分布作出的修正。然后我们把后验验分布最大化，这时的$$\theta$$就是我们想求解的参数的值。

总结一下，贝叶斯方法是通过最大化给定数据集的后验概率在估计参数的， 即：
```math
\theta^{*} = \arg\min\limits_{\theta}p(\theta|D)
```

根据贝叶斯公式：
```math
p(\theta|D) = \frac{p(D|\theta)p(\theta)}{p(D)}
```

其中，$$p(\theta)$$ 是$$\theta$$的概率密度函数，即先验分布，若$$\theta$$是一个连续的分布，则$$p(D) = \int_{\theta}p(D|\theta)p(\theta)d\theta$$，若$$\theta$$是一个离散的分布，则$$p(D) = \sum_{j=1}^{n}p(D|\theta_{j})p(\theta_{j})$$，其实当$$D$$和$$\theta$$是独立分布的时候，$$P(D)$$是和$$\theta$$无关的，这时我们简化为
```math
\theta^{*} = \arg\max\limits_{\theta}p(D|\theta)p(\theta)
```

取对数后

```math
\theta^{*} = \arg\max\limits_{\theta}\{\log (p(D|\theta)p(\theta)\}
```
```math
= \arg\max\limits_{\theta}\{\log p(D|\theta) + \log p(\theta)\}
```
```math
= \arg\max\limits_{\theta}\{\sum_{i=1}^{m}\log p(y^{(i)}|x^{(i)},\theta) + \log p(\theta)\}
```
```math
= \arg\min\limits_{\theta}\{\sum_{i=1}^{m}-\log p(y^{(i)}|x^{(i)},\theta) - \log p(\theta)\}
```

如果我们的损失函数采用的是对数损失，那前半部分就是经验风险函数。后面这部分是和$$\theta$$的分布有关。一般来说我们的经验就是模型要越就简单越好，因为我们希望$$\theta$$在$$0$$附近的概率会比较大。

若$$\theta$$服从期望是$$0$$，方差是$$\sigma$$的正态分布，则
```math
\theta^{*} = \arg\min\limits_{\theta}\{\sum_{i=1}^{m}-\log p(y^{(i)}|x^{(i)},\theta) - \sum_{j=1}^{n}\log \frac{1}{\sqrt{2\pi }\sigma}\exp(-\frac{\theta_{j}^{2}}{\sigma^{2}}) \}
```
```math
= \arg\min\limits_{\theta}\{\sum_{i=1}^{m}-\log p(y^{(i)}|x^{(i)},\theta) + \frac{1}{\sigma^{2}}\sum_{j=1}^{n}\theta_{j}^{2}
```
```math
= \arg\min\limits_{\theta}\{\sum_{i=1}^{m}-\log p(y^{(i)}|x^{(i)},\theta) + \frac{1}{\sigma^{2}}\|\theta||^{2}
```
令$$\lambda = \frac{1}{\sigma^{2}}$$，则后面那一项就是L2范式的正则化项。

若$$\theta$$服从期望是$$0$$，方差是$$b$$的拉普拉斯分布，则
```math
\theta^{*} = \arg\min\limits_{\theta}\{\sum_{i=1}^{m}-\log p(y^{(i)}|x^{(i)},\theta) - \sum_{j=1}^{n}\log \frac{1}{2b}\exp(-\frac{|\theta_{j}|}{b}) \}
```
```math
= \arg\min\limits_{\theta}\{\sum_{i=1}^{m}-\log p(y^{(i)}|x^{(i)},\theta) + \frac{1}{b}\sum_{j=1}^{n}|\theta_{j}|
```

令$$\lambda = \frac{1}{b}$$，则后面那一项就是L1范式的正则化项。

由此可见，正则化是由参数$$\theta$$的先验分布得来的，不同的先验分布对应着不同的正则化项，但这些分布有一个共同的特征就是期望为0，即希望模型更简单。
