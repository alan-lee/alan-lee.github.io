# 过拟合和欠拟合
在统计学中，拟合指的是你逼近目标函数的远近程度。

过拟合指的是模型对于训练数据拟合程度过当的情况。当某个模型过度的学习训练数据中的细节和噪音，以至于模型在新的数据上表现很差，我们称过拟合发生了。这意味着训练数据中的噪音或者随机波动也被当做概念被模型学习了。而问题就在于这些概念不适用于新的数据，从而导致模型泛化性能的变差。过拟合更可能在无参数非线性模型中发生，因为学习目标函数的过程是易变的具有弹性的。同样的，许多的无参数器学习算法也包括限制约束模型学习概念多少的参数或者技巧。

欠拟合指的是模型在训练和预测时表现都不好的情况。一个欠拟合的机器学习模型不是一个良好的模型并且由于在训练数据上表现不好这是显然的。欠拟合通常不被讨论，因为给定一个评估模型表现的指标的情况下，欠拟合很容易被发现。矫正方法是继续学习并且试着更换机器学习算法。

# 经验风险最小化
## 损失函数
在介绍很多监督学习算法时，都会给出损失函数，然后把监督学习问题变成一个最小化损失函数的最优化问题，设假设函数记为$$h(x)$$，则$$h(x)$$与样本结果$$y$$可能一致，也可能存在一定的误差，所以我们用一个函数来度量预测错误的程序，这个函数就是损失函数。损失函数是$$h(x)$$和$$y$$的函数，因为记为$$L(h(x), y)$$。

常用的损失函数有：
1. 0-1损失函数
```math
L(h(x), y) = \left\{\begin{matrix}
1, &  y \neq  h(x)
\\0, &  y = h(x)
\end{matrix}\right.
```
2. 平方损失函数
```math
L(h(x), y) = (y - h(x))^{2}
```

3. 对数损失函数
```math
L(p(y|x), y) = -\log p(y|x)
```

## 训练误差和测试误差



# 一致收敛

# Vapnik-Chervonenkis Dimension

# 结构风险最小化

# 交叉验证

# 正规化
